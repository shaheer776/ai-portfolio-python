{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb7dc00",
   "metadata": {},
   "source": [
    "# ðŸ§  PyTorch Basics\n",
    "\n",
    "This notebook provides a comprehensive introduction to **PyTorch**, covering essential topics, theory, functions, and practical examples. It's designed to help you understand the PyTorch framework for deep learning.\n",
    "\n",
    "ðŸ“˜ **Official Documentation**: [https://pytorch.org/docs/stable/index.html](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    "ðŸ“˜ **Official Pytorch Cheatsheet**: [https://docs.pytorch.org/tutorials/beginner/ptcheat.html](https://docs.pytorch.org/tutorials/beginner/ptcheat.html)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‘ Contents\n",
    "1. What is PyTorch?\n",
    "2. Tensors in PyTorch\n",
    "3. Tensor Operations\n",
    "4. Indexing and Slicing\n",
    "4. Autograd / Gradients\n",
    "5. Loss Functions\n",
    "6. Optimization\n",
    "7. Neural Network Modules\n",
    "8. GPU Acceleration with CUDA\n",
    "9. Saving and Loading Models\n",
    "10. Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50577335",
   "metadata": {},
   "source": [
    "## 1. What is PyTorch?\n",
    "\n",
    "**PyTorch** is an open-source machine learning library developed by Facebook AI. It's widely used for deep learning applications such as computer vision and natural language processing.\n",
    "\n",
    "- Tensor-based computation (like NumPy but with GPU support)\n",
    "- Dynamic computational graph\n",
    "- Powerful autograd engine\n",
    "- Supports CUDA for GPU acceleration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e5065",
   "metadata": {},
   "source": [
    "## 2. Tensor Creation Functions\n",
    "\n",
    "Tensors are the core data structure of PyTorch, similar to NumPy arrays but with GPU acceleration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e117d402",
   "metadata": {},
   "source": [
    "| Function           | Usage Description                             | Example                        |\n",
    "| ------------------ | --------------------------------------------- | ------------------------------ |\n",
    "| `torch.tensor()`   | Creates a tensor from data                    | `torch.tensor([1, 2, 3])`      |\n",
    "| `torch.zeros()`    | Creates a tensor filled with zeros            | `torch.zeros(2, 3)`            |\n",
    "| `torch.ones()`     | Creates a tensor filled with ones             | `torch.ones(3, 2)`             |\n",
    "| `torch.arange()`   | Returns evenly spaced values                  | `torch.arange(0, 10, 2)`       |\n",
    "| `torch.linspace()` | Returns values spaced evenly over an interval | `torch.linspace(0, 1, 5)`      |\n",
    "| `torch.rand()`     | Uniform random values in \\[0,1)               | `torch.rand(2, 2)`             |\n",
    "| `torch.randn()`    | Normal distribution values                    | `torch.randn(2, 2)`            |\n",
    "| `torch.randint()`  | Random ints from range                        | `torch.randint(0, 10, (2, 3))` |\n",
    "| `torch.eye()`      | Identity matrix                               | `torch.eye(3)`                 |\n",
    "| `torch.empty()`    | Uninitialized values (memory garbage)         | `torch.empty(2, 2)`            |\n",
    "\n",
    "These functions initialize tensors with specific values or patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# From data\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n",
    "\n",
    "# From NumPy array\n",
    "import numpy as np\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)\n",
    "\n",
    "# With random or constant values\n",
    "x_ones = torch.ones_like(x_data)\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(x_ones)\n",
    "print(x_rand)\n",
    "\n",
    "# With specific shape\n",
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff78cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Tensor from list:\", torch.tensor([1, 2, 3]))\n",
    "print(\"Zeros:\", torch.zeros(2, 2))\n",
    "print(\"Ones:\", torch.ones(2, 2))\n",
    "print(\"Arange:\", torch.arange(0, 10, 2))\n",
    "print(\"Linspace:\", torch.linspace(0, 1, 5))\n",
    "print(\"Rand:\", torch.rand(2, 2))\n",
    "print(\"Randn:\", torch.randn(2, 2))\n",
    "print(\"Randint:\", torch.randint(0, 10, (2, 2)))\n",
    "print(\"Eye:\", torch.eye(3))\n",
    "print(\"Empty:\", torch.empty(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b68de34",
   "metadata": {},
   "source": [
    "## 3. Tensor Operations\n",
    "\n",
    "PyTorch supports a wide range of tensor operations similar to NumPy.\n",
    "\n",
    "| Function            | Usage Description               | Example                      |\n",
    "| ------------------- | ------------------------------- | ---------------------------- |\n",
    "| `torch.add()`       | Element-wise addition           | `torch.add(t1, t2)`          |\n",
    "| `torch.sub()`       | Element-wise subtraction        | `torch.sub(t1, t2)`          |\n",
    "| `torch.mul()`       | Element-wise multiplication     | `torch.mul(t1, t2)`          |\n",
    "| `torch.div()`       | Element-wise division           | `torch.div(t1, t2)`          |\n",
    "| `torch.matmul()`    | Matrix multiplication           | `torch.matmul(t1, t2)`       |\n",
    "| `torch.mm()`        | Matrix multiplication (2D only) | `torch.mm(t1, t2)`           |\n",
    "| `torch.t()`         | Transpose 2D tensor             | `torch.t(t)`                 |\n",
    "| `torch.view()`      | Reshape tensor                  | `t.view(2, 6)`               |\n",
    "| `torch.reshape()`   | Reshape tensor                  | `t.reshape(3, 2)`            |\n",
    "| `torch.squeeze()`   | Remove dimensions of size 1     | `t.squeeze()`                |\n",
    "| `torch.unsqueeze()` | Add a dimension                 | `t.unsqueeze(0)`             |\n",
    "| `torch.cat()`       | Concatenate tensors             | `torch.cat((t1, t2), dim=0)` |\n",
    "| `torch.stack()`     | Stack tensors along new dim     | `torch.stack((t1, t2))`      |\n",
    "\n",
    "\n",
    "### Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6750b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addition\n",
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "z = x + y\n",
    "print(z)\n",
    "\n",
    "# Multiplication\n",
    "z = x * y\n",
    "print(z)\n",
    "\n",
    "# Matrix multiplication\n",
    "z = torch.matmul(x, y)\n",
    "print(z)\n",
    "\n",
    "# In-place operations\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Add:\", torch.add(a, b))\n",
    "print(\"Sub:\", torch.sub(a, b))\n",
    "print(\"Mul:\", torch.mul(a, b))\n",
    "print(\"Div:\", torch.div(a, b))\n",
    "print(\"Matmul:\", torch.matmul(a, b))\n",
    "print(\"View (reshape):\", a.view(4))\n",
    "print(\"Squeeze:\", torch.tensor([[[1]]]).squeeze())\n",
    "print(\"Unsqueeze:\", torch.tensor([1, 2]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b624c8",
   "metadata": {},
   "source": [
    "## 4. Indexing & Slicing\n",
    "\n",
    "Used to access elements or slices of tensors.\n",
    "\n",
    "| Function                | Usage Description         | Example                            |\n",
    "| ----------------------- | ------------------------- | ---------------------------------- |\n",
    "| `tensor[index]`         | Standard indexing         | `t[0]`, `t[:, 1]`                  |\n",
    "| `tensor[:], tensor[::]` | Slicing syntax            | `t[1:3]`                           |\n",
    "| `torch.gather()`        | Gather values along axis  | `torch.gather(t, 1, index_tensor)` |\n",
    "| `torch.masked_select()` | Select using boolean mask | `torch.masked_select(t, mask)`     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6174aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Indexing:\", t[1, 2])\n",
    "print(\"Slicing:\", t[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2da46",
   "metadata": {},
   "source": [
    "## 5. Autograd / Gradients\n",
    "\n",
    "PyTorch uses autograd for automatic differentiation, essential for training neural networks.\n",
    "\n",
    "| Function                | Usage Description                     | Example                              |\n",
    "| ----------------------- | ------------------------------------- | ------------------------------------ |\n",
    "| `.requires_grad_()`     | Enable gradient tracking              | `t.requires_grad_()`                 |\n",
    "| `.backward()`           | Compute gradients                     | `loss.backward()`                    |\n",
    "| `.grad`                 | Access gradients                      | `t.grad`                             |\n",
    "| `torch.autograd.grad()` | Compute and return gradients manually | `torch.autograd.grad(output, input)` |\n",
    "| `torch.no_grad()`       | Disable gradient tracking             | `with torch.no_grad(): ...`          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(out)\n",
    "\n",
    "# Backprop\n",
    "out.backward()\n",
    "print(x.grad)  # d(out)/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2\n",
    "y.backward()\n",
    "print(\"Gradient of x**2 w.r.t x:\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760b45a",
   "metadata": {},
   "source": [
    "## 6. Loss Functions\n",
    "\n",
    "Measure difference between prediction and target.\n",
    "\n",
    "| Function                      | Usage Description              | Example                               |\n",
    "| ----------------------------- | ------------------------------ | ------------------------------------- |\n",
    "| `torch.nn.MSELoss()`          | Mean squared error loss        | `loss = MSELoss()(pred, target)`      |\n",
    "| `torch.nn.CrossEntropyLoss()` | For multi-class classification | `loss = CrossEntropyLoss()(out, lbl)` |\n",
    "| `torch.nn.BCELoss()`          | Binary cross entropy           | `loss = BCELoss()(out, lbl)`          |\n",
    "| `F.nll_loss()`                | Negative log likelihood        | `F.nll_loss(pred, target)`            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "loss_fn = nn.MSELoss()\n",
    "pred = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "target = torch.tensor([1.5, 2.5])\n",
    "loss = loss_fn(pred, target)\n",
    "print(\"MSE Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726c9a9",
   "metadata": {},
   "source": [
    "## 7. Optimization\n",
    "\n",
    "Update model weights using gradients.\n",
    "\n",
    "| Function           | Usage Description                   | Example                                        |\n",
    "| ------------------ | ----------------------------------- | ---------------------------------------------- |\n",
    "| `torch.optim.SGD`  | Stochastic gradient descent         | `optimizer = SGD(model.parameters(), lr=0.01)` |\n",
    "| `torch.optim.Adam` | Adam optimizer                      | `optimizer = Adam(model.parameters())`         |\n",
    "| `.step()`          | Perform optimization step           | `optimizer.step()`                             |\n",
    "| `.zero_grad()`     | Zero gradients before backward pass | `optimizer.zero_grad()`                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd058c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "input = torch.tensor([[1.0, 2.0]])\n",
    "target = torch.tensor([[1.0]])\n",
    "output = model(input)\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c92175",
   "metadata": {},
   "source": [
    "## 8. Neural Network Modules\n",
    "\n",
    "PyTorch provides some modules to build neural networks.\n",
    "\n",
    "| Function                | Usage Description         | Example                              |\n",
    "| ----------------------- | ------------------------- | ------------------------------------ |\n",
    "| `torch.nn.Linear()`     | Fully connected layer     | `nn.Linear(128, 64)`                 |\n",
    "| `torch.nn.Conv2d()`     | Convolutional layer       | `nn.Conv2d(1, 16, 3)`                |\n",
    "| `torch.nn.ReLU()`       | ReLU activation           | `nn.ReLU()`                          |\n",
    "| `torch.nn.Sigmoid()`    | Sigmoid activation        | `nn.Sigmoid()`                       |\n",
    "| `torch.nn.Sequential()` | Stack layers sequentially | `nn.Sequential(nn.Linear(...), ...)` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3, 1)\n",
    ")\n",
    "print(\"Model architecture:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a383f",
   "metadata": {},
   "source": [
    "## 6. GPU Acceleration with CUDA\n",
    "\n",
    "Manage computation on CPU or GPU\n",
    "\n",
    "| Function                    | Usage Description              | Example                         |\n",
    "| --------------------------- | ------------------------------ | ------------------------------- |\n",
    "| `torch.device()`            | Define device                  | `device = torch.device(\"cuda\")` |\n",
    "| `.to(device)`               | Move tensor or model to device | `model.to(device)`              |\n",
    "| `torch.cuda.is_available()` | Check for GPU availability     | `torch.cuda.is_available()`     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bdf2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "x = torch.rand(5, 5).to(device)\n",
    "y = torch.rand(5, 5).to(device)\n",
    "z = x + y\n",
    "print(\"Tensor device:\", z.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6aefd4",
   "metadata": {},
   "source": [
    "## 7. Saving and Loading Models\n",
    "\n",
    "Save and reload model weights.\n",
    "\n",
    "| Function             | Usage Description            | Example                                       |\n",
    "| -------------------- | ---------------------------- | --------------------------------------------- |\n",
    "| `torch.save()`       | Save tensor or model         | `torch.save(model.state_dict(), \"model.pth\")` |\n",
    "| `torch.load()`       | Load tensor or model         | `state_dict = torch.load(\"model.pth\")`        |\n",
    "| `.load_state_dict()` | Load into model architecture | `model.load_state_dict(state_dict)`           |\n",
    "| `.eval()`            | Set model to evaluation mode | `model.eval()`                                |\n",
    "| `.train()`           | Set model to training mode   | `model.train()`                               |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model\n",
    "torch.save(net.state_dict(), 'model.pth')\n",
    "\n",
    "# Load model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4a441",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "- PyTorch is a powerful deep learning library\n",
    "- Core concept: Tensors\n",
    "- Supports autograd, GPU acceleration, and model training\n",
    "- Modular design: tensors, autograd, nn, optim\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
