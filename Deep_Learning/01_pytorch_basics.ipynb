{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb7dc00",
   "metadata": {},
   "source": [
    "# ðŸ§  PyTorch Basics\n",
    "\n",
    "This notebook provides a comprehensive introduction to **PyTorch**, covering essential topics, theory, functions, and practical examples. It's designed to help you understand the PyTorch framework for deep learning.\n",
    "\n",
    "ðŸ“˜ **Official Documentation**: [https://pytorch.org/docs/stable/index.html](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    "ðŸ“˜ **Official Pytorch Cheatsheet**: [https://docs.pytorch.org/tutorials/beginner/ptcheat.html](https://docs.pytorch.org/tutorials/beginner/ptcheat.html)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‘ Contents\n",
    "1. What is PyTorch?\n",
    "2. Tensors in PyTorch\n",
    "3. Tensor Operations\n",
    "4. Indexing and Slicing\n",
    "4. Autograd / Gradients\n",
    "5. Loss Functions\n",
    "6. Optimization\n",
    "7. Neural Network Modules\n",
    "8. GPU Acceleration with CUDA\n",
    "9. Saving and Loading Models\n",
    "10. Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50577335",
   "metadata": {},
   "source": [
    "## 1. What is PyTorch?\n",
    "\n",
    "**PyTorch** is an open-source machine learning library developed by Facebook AI. It's widely used for deep learning applications such as computer vision and natural language processing.\n",
    "\n",
    "- Tensor-based computation (like NumPy but with GPU support)\n",
    "- Dynamic computational graph\n",
    "- Powerful autograd engine\n",
    "- Supports CUDA for GPU acceleration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e5065",
   "metadata": {},
   "source": [
    "## 2. Tensor Creation Functions\n",
    "\n",
    "Tensors are the core data structure of PyTorch, similar to NumPy arrays but with GPU acceleration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e117d402",
   "metadata": {},
   "source": [
    "| Function           | Usage Description                             | Example                        |\n",
    "| ------------------ | --------------------------------------------- | ------------------------------ |\n",
    "| `torch.tensor()`   | Creates a tensor from data                    | `torch.tensor([1, 2, 3])`      |\n",
    "| `torch.zeros()`    | Creates a tensor filled with zeros            | `torch.zeros(2, 3)`            |\n",
    "| `torch.ones()`     | Creates a tensor filled with ones             | `torch.ones(3, 2)`             |\n",
    "| `torch.arange()`   | Returns evenly spaced values                  | `torch.arange(0, 10, 2)`       |\n",
    "| `torch.linspace()` | Returns values spaced evenly over an interval | `torch.linspace(0, 1, 5)`      |\n",
    "| `torch.rand()`     | Uniform random values in \\[0,1)               | `torch.rand(2, 2)`             |\n",
    "| `torch.randn()`    | Normal distribution values                    | `torch.randn(2, 2)`            |\n",
    "| `torch.randint()`  | Random ints from range                        | `torch.randint(0, 10, (2, 3))` |\n",
    "| `torch.eye()`      | Identity matrix                               | `torch.eye(3)`                 |\n",
    "| `torch.empty()`    | Uninitialized values (memory garbage)         | `torch.empty(2, 2)`            |\n",
    "\n",
    "These functions initialize tensors with specific values or patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17d26a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.6961, 0.6508],\n",
      "        [0.8906, 0.5505]])\n",
      "tensor([[0.7404, 0.5891, 0.6816],\n",
      "        [0.6025, 0.9174, 0.5807]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# From data\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n",
    "\n",
    "# From NumPy array\n",
    "import numpy as np\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)\n",
    "\n",
    "# With random or constant values\n",
    "x_ones = torch.ones_like(x_data)\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(x_ones)\n",
    "print(x_rand)\n",
    "\n",
    "# With specific shape\n",
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff78cf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from list: tensor([1, 2, 3])\n",
      "Zeros: tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "Ones: tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "Arange: tensor([0, 2, 4, 6, 8])\n",
      "Linspace: tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
      "Rand: tensor([[0.7182, 0.5519],\n",
      "        [0.4947, 0.1440]])\n",
      "Randn: tensor([[ 1.5066, -0.7911],\n",
      "        [ 0.7500, -0.0727]])\n",
      "Randint: tensor([[4, 9],\n",
      "        [3, 9]])\n",
      "Eye: tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "Empty: tensor([[ 0.0000, 18.9802],\n",
      "        [ 0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Tensor from list:\", torch.tensor([1, 2, 3]))\n",
    "print(\"Zeros:\", torch.zeros(2, 2))\n",
    "print(\"Ones:\", torch.ones(2, 2))\n",
    "print(\"Arange:\", torch.arange(0, 10, 2))\n",
    "print(\"Linspace:\", torch.linspace(0, 1, 5))\n",
    "print(\"Rand:\", torch.rand(2, 2))\n",
    "print(\"Randn:\", torch.randn(2, 2))\n",
    "print(\"Randint:\", torch.randint(0, 10, (2, 2)))\n",
    "print(\"Eye:\", torch.eye(3))\n",
    "print(\"Empty:\", torch.empty(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b68de34",
   "metadata": {},
   "source": [
    "## 3. Tensor Operations\n",
    "\n",
    "PyTorch supports a wide range of tensor operations similar to NumPy.\n",
    "\n",
    "| Function            | Usage Description               | Example                      |\n",
    "| ------------------- | ------------------------------- | ---------------------------- |\n",
    "| `torch.add()`       | Element-wise addition           | `torch.add(t1, t2)`          |\n",
    "| `torch.sub()`       | Element-wise subtraction        | `torch.sub(t1, t2)`          |\n",
    "| `torch.mul()`       | Element-wise multiplication     | `torch.mul(t1, t2)`          |\n",
    "| `torch.div()`       | Element-wise division           | `torch.div(t1, t2)`          |\n",
    "| `torch.matmul()`    | Matrix multiplication           | `torch.matmul(t1, t2)`       |\n",
    "| `torch.mm()`        | Matrix multiplication (2D only) | `torch.mm(t1, t2)`           |\n",
    "| `torch.t()`         | Transpose 2D tensor             | `torch.t(t)`                 |\n",
    "| `torch.view()`      | Reshape tensor                  | `t.view(2, 6)`               |\n",
    "| `torch.reshape()`   | Reshape tensor                  | `t.reshape(3, 2)`            |\n",
    "| `torch.squeeze()`   | Remove dimensions of size 1     | `t.squeeze()`                |\n",
    "| `torch.unsqueeze()` | Add a dimension                 | `t.unsqueeze(0)`             |\n",
    "| `torch.cat()`       | Concatenate tensors             | `torch.cat((t1, t2), dim=0)` |\n",
    "| `torch.stack()`     | Stack tensors along new dim     | `torch.stack((t1, t2))`      |\n",
    "\n",
    "\n",
    "### Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e6750b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5275, 1.0413],\n",
      "        [0.4973, 1.1403]])\n",
      "tensor([[0.5325, 0.2468],\n",
      "        [0.0362, 0.2164]])\n",
      "tensor([[0.5924, 0.8052],\n",
      "        [0.4257, 0.3655]])\n",
      "tensor([[1.5275, 1.0413],\n",
      "        [0.4973, 1.1403]])\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "z = x + y\n",
    "print(z)\n",
    "\n",
    "# Multiplication\n",
    "z = x * y\n",
    "print(z)\n",
    "\n",
    "# Matrix multiplication\n",
    "z = torch.matmul(x, y)\n",
    "print(z)\n",
    "\n",
    "# In-place operations\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "098b772e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add: tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "Sub: tensor([[-4, -4],\n",
      "        [-4, -4]])\n",
      "Mul: tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "Div: tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]])\n",
      "Matmul: tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "View (reshape): tensor([1, 2, 3, 4])\n",
      "Squeeze: tensor(1)\n",
      "Unsqueeze: tensor([[1, 2]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"Add:\", torch.add(a, b))\n",
    "print(\"Sub:\", torch.sub(a, b))\n",
    "print(\"Mul:\", torch.mul(a, b))\n",
    "print(\"Div:\", torch.div(a, b))\n",
    "print(\"Matmul:\", torch.matmul(a, b))\n",
    "print(\"View (reshape):\", a.view(4))\n",
    "print(\"Squeeze:\", torch.tensor([[[1]]]).squeeze())\n",
    "print(\"Unsqueeze:\", torch.tensor([1, 2]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b624c8",
   "metadata": {},
   "source": [
    "## 4. Indexing & Slicing\n",
    "\n",
    "Used to access elements or slices of tensors.\n",
    "\n",
    "| Function                | Usage Description         | Example                            |\n",
    "| ----------------------- | ------------------------- | ---------------------------------- |\n",
    "| `tensor[index]`         | Standard indexing         | `t[0]`, `t[:, 1]`                  |\n",
    "| `tensor[:], tensor[::]` | Slicing syntax            | `t[1:3]`                           |\n",
    "| `torch.gather()`        | Gather values along axis  | `torch.gather(t, 1, index_tensor)` |\n",
    "| `torch.masked_select()` | Select using boolean mask | `torch.masked_select(t, mask)`     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6174aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing: tensor(6)\n",
      "Slicing: tensor([[2, 3],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Indexing:\", t[1, 2])\n",
    "print(\"Slicing:\", t[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2da46",
   "metadata": {},
   "source": [
    "## 5. Autograd / Gradients\n",
    "\n",
    "PyTorch uses autograd for automatic differentiation, essential for training neural networks.\n",
    "\n",
    "| Function                | Usage Description                     | Example                              |\n",
    "| ----------------------- | ------------------------------------- | ------------------------------------ |\n",
    "| `.requires_grad_()`     | Enable gradient tracking              | `t.requires_grad_()`                 |\n",
    "| `.backward()`           | Compute gradients                     | `loss.backward()`                    |\n",
    "| `.grad`                 | Access gradients                      | `t.grad`                             |\n",
    "| `torch.autograd.grad()` | Compute and return gradients manually | `torch.autograd.grad(output, input)` |\n",
    "| `torch.no_grad()`       | Disable gradient tracking             | `with torch.no_grad(): ...`          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aca759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(out)\n",
    "\n",
    "# Backprop\n",
    "out.backward()\n",
    "print(x.grad)  # d(out)/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d976c7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of x**2 w.r.t x: tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x**2\n",
    "y.backward()\n",
    "print(\"Gradient of x**2 w.r.t x:\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f760b45a",
   "metadata": {},
   "source": [
    "## 6. Loss Functions\n",
    "\n",
    "Measure difference between prediction and target.\n",
    "\n",
    "| Function                      | Usage Description              | Example                               |\n",
    "| ----------------------------- | ------------------------------ | ------------------------------------- |\n",
    "| `torch.nn.MSELoss()`          | Mean squared error loss        | `loss = MSELoss()(pred, target)`      |\n",
    "| `torch.nn.CrossEntropyLoss()` | For multi-class classification | `loss = CrossEntropyLoss()(out, lbl)` |\n",
    "| `torch.nn.BCELoss()`          | Binary cross entropy           | `loss = BCELoss()(out, lbl)`          |\n",
    "| `F.nll_loss()`                | Negative log likelihood        | `F.nll_loss(pred, target)`            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37fd1d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.25\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "loss_fn = nn.MSELoss()\n",
    "pred = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "target = torch.tensor([1.5, 2.5])\n",
    "loss = loss_fn(pred, target)\n",
    "print(\"MSE Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726c9a9",
   "metadata": {},
   "source": [
    "## 7. Optimization\n",
    "\n",
    "Update model weights using gradients.\n",
    "\n",
    "| Function           | Usage Description                   | Example                                        |\n",
    "| ------------------ | ----------------------------------- | ---------------------------------------------- |\n",
    "| `torch.optim.SGD`  | Stochastic gradient descent         | `optimizer = SGD(model.parameters(), lr=0.01)` |\n",
    "| `torch.optim.Adam` | Adam optimizer                      | `optimizer = Adam(model.parameters())`         |\n",
    "| `.step()`          | Perform optimization step           | `optimizer.step()`                             |\n",
    "| `.zero_grad()`     | Zero gradients before backward pass | `optimizer.zero_grad()`                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd058c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "input = torch.tensor([[1.0, 2.0]])\n",
    "target = torch.tensor([[1.0]])\n",
    "output = model(input)\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c92175",
   "metadata": {},
   "source": [
    "## 8. Neural Network Modules\n",
    "\n",
    "PyTorch provides some modules to build neural networks.\n",
    "\n",
    "| Function                | Usage Description         | Example                              |\n",
    "| ----------------------- | ------------------------- | ------------------------------------ |\n",
    "| `torch.nn.Linear()`     | Fully connected layer     | `nn.Linear(128, 64)`                 |\n",
    "| `torch.nn.Conv2d()`     | Convolutional layer       | `nn.Conv2d(1, 16, 3)`                |\n",
    "| `torch.nn.ReLU()`       | ReLU activation           | `nn.ReLU()`                          |\n",
    "| `torch.nn.Sigmoid()`    | Sigmoid activation        | `nn.Sigmoid()`                       |\n",
    "| `torch.nn.Sequential()` | Stack layers sequentially | `nn.Sequential(nn.Linear(...), ...)` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe8d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture: Sequential(\n",
      "  (0): Linear(in_features=4, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3, 1)\n",
    ")\n",
    "print(\"Model architecture:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed5f20a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a383f",
   "metadata": {},
   "source": [
    "## 6. GPU Acceleration with CUDA\n",
    "\n",
    "Manage computation on CPU or GPU\n",
    "\n",
    "| Function                    | Usage Description              | Example                         |\n",
    "| --------------------------- | ------------------------------ | ------------------------------- |\n",
    "| `torch.device()`            | Define device                  | `device = torch.device(\"cuda\")` |\n",
    "| `.to(device)`               | Move tensor or model to device | `model.to(device)`              |\n",
    "| `torch.cuda.is_available()` | Check for GPU availability     | `torch.cuda.is_available()`     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20bdf2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "x = torch.rand(5, 5).to(device)\n",
    "y = torch.rand(5, 5).to(device)\n",
    "z = x + y\n",
    "print(\"Tensor device:\", z.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6aefd4",
   "metadata": {},
   "source": [
    "## 7. Saving and Loading Models\n",
    "\n",
    "Save and reload model weights.\n",
    "\n",
    "| Function             | Usage Description            | Example                                       |\n",
    "| -------------------- | ---------------------------- | --------------------------------------------- |\n",
    "| `torch.save()`       | Save tensor or model         | `torch.save(model.state_dict(), \"model.pth\")` |\n",
    "| `torch.load()`       | Load tensor or model         | `state_dict = torch.load(\"model.pth\")`        |\n",
    "| `.load_state_dict()` | Load into model architecture | `model.load_state_dict(state_dict)`           |\n",
    "| `.eval()`            | Set model to evaluation mode | `model.eval()`                                |\n",
    "| `.train()`           | Set model to training mode   | `model.train()`                               |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36ba181a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save model\n",
    "torch.save(net.state_dict(), 'model.pth')\n",
    "\n",
    "# Load model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4a441",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "- PyTorch is a powerful deep learning library\n",
    "- Core concept: Tensors\n",
    "- Supports autograd, GPU acceleration, and model training\n",
    "- Modular design: tensors, autograd, nn, optim\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
